{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports & Setup\n",
    "\n",
    "\"\"\"\n",
    "Description: Flags duplicate patients in the argument .csv file by adding a column called 'Flag' that maps to\n",
    "             unique user tests. Thus, the number in the 'Flag' column for any given row will only match to duplicate\n",
    "             persons\n",
    "\n",
    "Sample Usage: Use 'python3 flag_duplicates.py [$filename$.csv]' to flag all duplicates and output a new .csv to the path\n",
    "./filename.flagged_duplicates.csv, where filename is replaced with a \n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import sys\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading in data\n",
    "\n",
    "# Ensuring that a file path has been passed into the script\n",
    "improper_arg_msg = \"Improper arguments passed in - use 'python3 flag_duplicates.py [$filename$.csv]'\"\n",
    "if len(sys.argv) < 2:\n",
    "    assert False, improper_arg_msg\n",
    "elif \".csv\" not in sys.argv[1]:\n",
    "    print(\"Using the sample dataset...\\n\", improper_arg_msg)\n",
    "    sys.argv[1] = \"deduplicator_sample_data_scramble.csv\"\n",
    "\n",
    "\n",
    "# Getting the roster and homework response paths\n",
    "path = sys.argv[1]\n",
    "\n",
    "lab_confirmed_flu = pd.read_csv(sys.argv[1])\n",
    "lab_confirmed_flu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Find Fuzzy string matches for each Patient\n",
    "try:\n",
    "    patients = lab_confirmed_flu[\"Patient\"]\n",
    "except:\n",
    "    try:\n",
    "        lab_confirmed_flu[\"Patient\"] = np.core.defchararray.add(lab_confirmed_flu['last_name'],\n",
    "                                                                lab_confirmed_flu['first_name'])\n",
    "    except:\n",
    "        lab_confirmed_flu[\"Patient\"] = (np.asarray(lab_confirmed_flu[\"last_name\"]) + \n",
    "                                        \" \" + \n",
    "                                        np.asarray(lab_confirmed_flu.first_name)\n",
    "                                       )\n",
    "    \n",
    "    \n",
    "    patients = lab_confirmed_flu[\"Patient\"]\n",
    "\n",
    "#The first match of each list will be the row the patient was from\n",
    "matches = [process.extract(query=patient, \n",
    "                           choices=patients, \n",
    "                           limit=max(25, \n",
    "                                     int(len(patients) ** .5)) \n",
    "                          )\n",
    "           for patient in patients]\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Find true duplicates and match them up\n",
    "\n",
    "#Maps frozenset tuples of 2 filtered match indices >> patient index (-1 if they are not true matches)\n",
    "filtered_match_ids = dict()\n",
    "#The column to be added, containing the updated patient_id for each index\n",
    "flags = np.arange( len(patients) )\n",
    "#Ensures that one patient's index is not set multiple times (a single patient's index should not match via manual and automated detection more than once)\n",
    "already_matched = set()\n",
    "#Keeps track of all matches for displaying later\n",
    "all_matches_in_dataset = []\n",
    "\n",
    "def validate_matches(filtered_match_index, filtered_match_ids):\n",
    "    \"\"\"For a given filtered_match_index, returns whether all keys in filtered_match_ids that have filtered_match_index within the key have the same value\n",
    "        :param int filtered_match_index : the index of a match\n",
    "        :param dict filtered_match_ids  : Maps frozenset tuples of 2 filtered match indices >> patient index (-1 if they are not true matches)\n",
    "        :return boolean                 : whether all keys in filtered_match_ids that have filtered_match_index within the key map to the same value\n",
    "    \"\"\"\n",
    "    match_keys = [key for key in filtered_match_ids if filtered_match_index in key and filtered_match_ids[key] != -1]\n",
    "    reference_value = filtered_match_ids[ match_keys[0] ]\n",
    "    for key in match_keys:\n",
    "        if filtered_match_ids[key] != reference_value: return False  \n",
    "    return True\n",
    "    \n",
    "for patient_match_list in matches:\n",
    "    patient = patient_match_list[0]\n",
    "    patient_index = int(patient[2])\n",
    "    \n",
    "    #Narrow down all fuzzy string scores to only potential duplicates of \"patient\"\n",
    "    all_matches = np.asarray(patient_match_list[1:])\n",
    "    filtered_matches = all_matches[ np.asarray([int(match[1]) > 65 for match in all_matches]) ]\n",
    "    \n",
    "    #For all filtered matches, find true duplicates and give them the same patient_id\n",
    "    #Note: simply because another patient passed the filter does NOT mean they are a true match \n",
    "    for filtered_match in filtered_matches:\n",
    "        \n",
    "        filtered_match_index = int(filtered_match[2])\n",
    "        possible_match_key = frozenset([patient_index, filtered_match_index])\n",
    "        \n",
    "        #If this possible_match_key has already been checked and IS NOT a match\n",
    "        if possible_match_key in filtered_match_ids and filtered_match_ids[possible_match_key] == -1:\n",
    "\n",
    "            continue\n",
    "            \n",
    "        #If this possible_match_key has already been checked and IS a match, use the same value\n",
    "        elif possible_match_key in filtered_match_ids:\n",
    "            \n",
    "            flags[patient_index] = filtered_match_ids[possible_match_key]\n",
    "            break\n",
    "        \n",
    "        #If the possible_match_key has not already been checked, determine whether it is a true match\n",
    "        else:\n",
    "            patient_row        = lab_confirmed_flu.iloc[patient_index]\n",
    "            filtered_match_row = lab_confirmed_flu.iloc[filtered_match_index]\n",
    "            \n",
    "            #Uncertain based on data -- ask user to take a closer look\n",
    "            if ( (type(patient_row.DOB)               == float and np.isnan(patient_row.DOB ))        or\n",
    "                 (type(filtered_match_row.DOB)        == float and np.isnan(filtered_match_row.DOB )) or\n",
    "                 (type(patient_row.Collected)         == float and np.isnan(patient_row.Collected  )) or   \n",
    "                 (type(filtered_match_row.Collected)  == float and np.isnan(filtered_match_row.Collected))\n",
    "               ):\n",
    "                \n",
    "                msg = \"\"\"Please press 'Y' if the two patients are matches and anything else if they are not: \"\"\"\n",
    "                print(\"\\n\\n===========================================================\\nPlease examine the following:\\n\")\n",
    "                print(\"\\tTarget Patient:\\n\", patient_row)\n",
    "                print(\"\\tPotential match:\\n\", filtered_match_row)\n",
    "                is_match = input(\"\\n\"+msg).strip().lower() == 'y'\n",
    "                \n",
    "            #Highly probable matches based on DOB + Collection Time + Test\n",
    "            else:                \n",
    "\n",
    "                DOB_match       = patient_row[\"DOB\"]       == filtered_match_row[\"DOB\"]\n",
    "                Collected_match = patient_row[\"Collected\"] == filtered_match_row[\"Collected\"]\n",
    "                \n",
    "                try:\n",
    "                    Test_match  = patient_row[\"Test\"]      == filtered_match_row[\"Test\"]\n",
    "                \n",
    "                except: #cc.dedup\n",
    "                    try:\n",
    "                        Test_match  = patient_row['Result']== filtered_match_row['Result']   \n",
    "                    \n",
    "                    except: #cho.a.dedup\n",
    "                        try:\n",
    "                            Test_match  = patient_row['flua']  == filtered_match_row['flua'] and patient_row['flub']  == filtered_match_row['flub'] \n",
    "                        \n",
    "                        except: #cho.b.dedup\n",
    "                            try:\n",
    "                                Test_match  = (patient_row['influenza.a.h1']  == filtered_match_row['influenza.a.h1'] and \n",
    "                                               patient_row['influenza.a.h3']  == filtered_match_row['influenza.a.h3'] and \n",
    "                                               patient_row['x2009.inf.a.h1n1.rvp']  == filtered_match_row['x2009.inf.a.h1n1.rvp'] and\n",
    "                                               patient_row['flu.b']  == filtered_match_row['flu.b'] and\n",
    "                                               patient_row['rsv.a']  == filtered_match_row['rsv.a'] and\n",
    "                                               patient_row['rsv.b']  == filtered_match_row['rsv.b'] and\n",
    "                                               patient_row['parainfluenza.1']  == filtered_match_row['parainfluenza.1'] and\n",
    "                                               patient_row['parainfluenza.2']  == filtered_match_row['parainfluenza.2'] and\n",
    "                                               patient_row['parainfluenza.3']  == filtered_match_row['parainfluenza.3'] and\n",
    "                                               patient_row['rhinovirus']  == filtered_match_row['rhinovirus'] and\n",
    "                                               patient_row['adenovirus']  == filtered_match_row['adenovirus'] and\n",
    "                                               patient_row['metapneumovirus']  == filtered_match_row['metapneumovirus']\n",
    "                                              )\n",
    "                            except: #CEIP Shoo the Flu \n",
    "                                try:\n",
    "                                    Test_match = (patient_row['FLU TEST TYPE']  == filtered_match_row['FLU TEST TYPE'] and \n",
    "                                                  patient_row['INFLUENZA ANTIGEN DETECTION']  == filtered_match_row['INFLUENZA ANTIGEN DETECTION'] and \n",
    "                                                  patient_row['FLU B']  == filtered_match_row['FLU B'] and\n",
    "                                                  patient_row['INFLUENZA A H1']  == filtered_match_row['INFLUENZA A H1'] and\n",
    "                                                  patient_row['INFLUENZA A H3']  == filtered_match_row['INFLUENZA A H3'] and\n",
    "                                                  patient_row['2009 INF A/H1N1 RVP']  == filtered_match_row['2009 INF A/H1N1 RVP'] and\n",
    "                                                  patient_row['RSV A']  == filtered_match_row['RSV A'] and\n",
    "                                                  patient_row['RSV B']  == filtered_match_row['RSV B'] and\n",
    "                                                  patient_row['PARAINFLUENZA 1']  == filtered_match_row['PARAINFLUENZA 1'] and\n",
    "                                                  patient_row['PARAINFLUENZA 2']  == filtered_match_row['PARAINFLUENZA 2'] and\n",
    "                                                  patient_row['PARAINFLUENZA 3']  == filtered_match_row['PARAINFLUENZA 3']\n",
    "                                                 )\n",
    "                                \n",
    "                                except:\n",
    "                                    assert False, \"All cases should've been covered\"\n",
    "                                    print(path)\n",
    "                                    print(\"\\n\\nSample Patient Row:\\n\\n\")\n",
    "                                    print(patient_row)\n",
    "                            \n",
    "                is_match = DOB_match and Collected_match and Test_match\n",
    "\n",
    "            #Storing the result of our comparison in filtered_match_ids\n",
    "            if is_match:\n",
    "                \n",
    "                all_matches_in_dataset.append(patient_row)\n",
    "                \n",
    "                contradiction_msg = \"The newly matched patient has already been matched -- this is a contradiction. Patient: \" + str(patient)\n",
    "                assert (filtered_match_index not in already_matched) or validate_matches(filtered_match_index, filtered_match_ids), contradiction_msg \n",
    "                \n",
    "                filtered_match_ids[possible_match_key] = flags[patient_index]\n",
    "                flags[filtered_match_index] = flags[patient_index]\n",
    "                already_matched.add(filtered_match_index)\n",
    "            \n",
    "            else:           \n",
    "                filtered_match_ids[possible_match_key] = -1\n",
    "        \n",
    "lab_confirmed_flu[\"Flag\"] = flags \n",
    "lab_confirmed_flu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the result\n",
    "\n",
    "assert path[-4:] == \".csv\"\n",
    "new_path = path[:-4] + \".flagged_duplicates.csv\"\n",
    "\n",
    "lab_confirmed_flu.to_csv(path_or_buf=new_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(all_matches_in_dataset) > 0:\n",
    "    print(\"Dataset:\", new_path)\n",
    "    print(\"All matches in dataset:\\n\\n\", all_matches_in_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
